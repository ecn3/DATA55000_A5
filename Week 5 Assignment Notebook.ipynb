{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5 Notebook - Multilayered Perceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayered Perceptrons for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3    9.3\n",
       "3  151.5   41.3       58.5   18.5\n",
       "4  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.collections import LineCollection\n",
    "from mpl_toolkits.mplot3d.art3d import Line3DCollection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "np.random.seed = 47\n",
    "\n",
    "advertising = pd.read_csv('Advertising.csv',usecols=(1,2,3,4))\n",
    "\n",
    "advertising.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(advertising['TV']).reshape(-1,1)\n",
    "y = np.array(advertising['Sales'])\n",
    "\n",
    "X_train, X_test, y_train, y_test =train_test_split(\n",
    "    X, y, test_size=0.2, random_state=9)\n",
    "\n",
    "stdscaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_scaled = stdscaler.transform(X_train)\n",
    "X_test_scaled  = stdscaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your code here\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.regularizers import l2, l1\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Stochastic Logistic Regression\n",
    "model = Sequential()\n",
    "\n",
    "# Model \n",
    "model.add(Dense(units=2, input_shape=[X_train_scaled.shape[1]], \n",
    "                activation='sigmoid'))\n",
    "model.add(Dense(units=1, activation='linear'))\n",
    "\n",
    "# Slightly better model.\n",
    "# model.add(Dense(output_dim=4, input_shape=[X_train_scaled.shape[1]], \n",
    "#                 activation='relu'))\n",
    "# model.add(Dense(output_dim=2, activation='sigmoid'))\n",
    "# model.add(Dense(output_dim=1, activation='linear'))\n",
    "\n",
    "\n",
    "# Compile model\n",
    "sgd = SGD(lr=0.001)\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "history = model.fit(X_train_scaled, y_train.reshape(-1,1), batch_size = 256,\n",
    "          epochs = 10000, verbose=0, validation_data=(X_test_scaled,y_test.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(6,4))\n",
    "# # summarize history for loss\n",
    "plt.plot(np.sqrt(history.history['loss']))\n",
    "plt.plot(np.sqrt(history.history['val_loss']), 'g--')\n",
    "plt.title('MLP Regression Model Loss')\n",
    "plt.ylabel('Root Mean Squared Error (RMSE)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training Loss', 'Testing Loss'], loc='upper right')\n",
    "print(\"RMSE Loss after final iteration: \", np.sqrt(history.history['val_loss'][-1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "y_predicted = model.predict(X_train_scaled)\n",
    "N = len(y_train)\n",
    "\n",
    "segments = [[[X_train_scaled[i], y_train[i]], [X_train_scaled[i], y_predicted[i]]] for i in range(N)]\n",
    "lc = LineCollection(segments, zorder=0)\n",
    "lc.set_array(np.ones(len(y_train)))\n",
    "lc.set_alpha(0.5)\n",
    "lc.set_linewidths(0.5 * np.ones(len(y_train)))\n",
    "\n",
    "fig = plt.figure(figsize=[24,10])\n",
    "# plot the training data\n",
    "plt.plot(X_train_scaled, y_train, 'r.', markersize=12)\n",
    "# plot the prediction line\n",
    "x_lin = np.linspace(X_train_scaled.min(),X_train_scaled.max(),1000).reshape(-1,1)\n",
    "plt.plot(x_lin, model.predict(x_lin), color='blue',linewidth=3,alpha=0.5)\n",
    "# plot the redisuals\n",
    "plt.gca().add_collection(lc)\n",
    "\n",
    "plt.xlim([X_train_scaled.min(),X_train_scaled.max()])\n",
    "plt.xlabel('TV advertisement budget')\n",
    "plt.ylabel('Sales')\n",
    "plt.legend(('Data', 'Regression Fit'), loc='lower right')\n",
    "plt.title('Neural Network regression')\n",
    "\n",
    "# plot the regression line\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KDD Cup 1999 Network Security Dataset\n",
    "\n",
    "In this next example, we will look at the KDD Cup 1999 dataset. (10% subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.regularizers import l2,l1\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "np.random.seed = 47\n",
    "\n",
    "data = pd.read_csv('kddcup.data_10_percent.csv',header=None)\n",
    "dataCols = ['duration','protocol_type','service','flag','src_bytes','dst_bytes',\n",
    "    'land','wrong_fragment','urgent','hot','num_failed_logins','logged_in','num_compromised',\n",
    "    'root_shell','su_attempted','num_root','num_file_creations','num_shells',\n",
    "    'num_access_files','num_outbound_cmds','is_host_login','is_guest_login',\n",
    "    'count','srv_count','serror_rate','srv_serror_rate','rerror_rate','srv_rerror_rate',\n",
    "    'same_srv_rate','diff_srv_rate','srv_diff_host_rate','dst_host_count','dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate','dst_host_diff_srv_rate','dst_host_same_src_port_rate',\n",
    "    'dst_host_srv_diff_host_rate','dst_host_serror_rate','dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate','dst_host_srv_rerror_rate','target']\n",
    "data.columns = dataCols\n",
    "\n",
    "print(\"Shape: \", data.shape)\n",
    "print(\"Targets: \", data['target'].unique())\n",
    "data = data.reindex(np.random.permutation(data.index)).reset_index(drop=True)\n",
    "\n",
    "target = data['target'].copy()\n",
    "data = data.drop('target', axis=1)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discreteCols = ['protocol_type','service','flag']\n",
    "dataDummies = pd.get_dummies(data[discreteCols])\n",
    "data = data.drop(discreteCols, axis=1)\n",
    "\n",
    "data = dataDummies.join(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posteriorCount = {i:(target==i).sum() for i in target.unique()}\n",
    "fig = plt.figure(figsize=(20,8))\n",
    "plt.bar(range(len(posteriorCount)), posteriorCount.values(), align='center')\n",
    "plt.xticks(range(len(posteriorCount)), zip(posteriorCount.keys(),posteriorCount.values()), rotation='vertical')\n",
    "plt.subplots_adjust(bottom=0.15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetDummies = pd.get_dummies(target)\n",
    "targetFull = targetDummies\n",
    "targetFull.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target[target != 'normal.'] = 1.0\n",
    "target[target == 'normal.'] = 0.0\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posteriorCount = {i:(target==i).sum() for i in target.unique()}\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "plt.bar(range(len(posteriorCount)), posteriorCount.values(), align='center')\n",
    "plt.xticks(range(len(posteriorCount)), zip(posteriorCount.keys(),posteriorCount.values()), rotation='vertical')\n",
    "plt.subplots_adjust(bottom=0.15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test =train_test_split(\n",
    "    data, target, test_size=0.5, random_state=50)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test  = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test  = y_test.reset_index(drop=True)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the data\n",
    "# turn off the error message, we're not setting indivdual values.\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "toStandardize = ['src_bytes', 'dst_bytes', 'count', 'srv_count',\n",
    "                 'dst_host_count', 'dst_host_srv_count']\n",
    "stdscaler = preprocessing.MinMaxScaler().fit(X_train[toStandardize])\n",
    "X_train[toStandardize] = stdscaler.transform(X_train[toStandardize])\n",
    "X_test[toStandardize]  = stdscaler.transform(X_test[toStandardize])\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model on the KDD Cup 1999 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.regularizers import l2, l1\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Stochastic Logistic Regression\n",
    "model = Sequential()\n",
    "\n",
    "# Model\n",
    "model.add(Dense(units=1, input_shape=[X_train.shape[1]], \n",
    "                activation='sigmoid', kernel_regularizer=l2(0.001)))\n",
    "\n",
    "# Compile model\n",
    "sgd = SGD(lr=0.1)\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "history = model.fit(X_train.to_numpy(), y_train.to_numpy().reshape(-1,1), batch_size = 256,\n",
    "          epochs = 15, verbose=2, validation_data=(X_test.to_numpy(),y_test.to_numpy().reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(6,4))\n",
    "# # summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'], 'g--')\n",
    "plt.title('Logistic Regression Model Loss')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training Loss', 'Testing Loss'], loc='upper right')\n",
    "print(\"Loss after final iteration: \", history.history['val_loss'][-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (pd.DataFrame(model.predict(X_test.to_numpy())))\n",
    "\n",
    "M11= predictions.to_numpy()\n",
    "\n",
    "predictions[M11 > (0.5)] = 'normal'\n",
    "predictions[M11 <= (0.5)] = 'anamoly'\n",
    "\n",
    "My11=y_test.to_numpy().reshape(-1,1).copy()\n",
    "\n",
    "y_test_labels = y_test.to_numpy().reshape(-1,1).copy()\n",
    "y_test_labels[My11 > 0.5] = 'normal'\n",
    "y_test_labels[My11 <= 0.5] = 'anamoly'\n",
    "\n",
    "print('accuracy', accuracy_score(predictions,y_test_labels))\n",
    "print('confusion matrix\\n', confusion_matrix(predictions,y_test_labels))\n",
    "\n",
    "print(classification_report(predictions,y_test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Model on the KDD Cup 1999 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.regularizers import l2, l1\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Stochastic Logistic Regression\n",
    "model = Sequential()\n",
    "\n",
    "# Model\n",
    "model.add(Dense(units=4, input_shape=[X_train.shape[1]], \n",
    "                activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(units=2, \n",
    "                activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dense(units=1,\n",
    "                activation='sigmoid', kernel_regularizer=l2(0.001)))\n",
    "# Compile model\n",
    "sgd = SGD(lr=0.1)\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "history = model.fit(X_train.to_numpy(), y_train.to_numpy().reshape(-1,1), batch_size = 256,\n",
    "          epochs = 15, verbose=2, validation_data=(X_test.to_numpy(),y_test.to_numpy().reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(6,4))\n",
    "# # summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'], 'g--')\n",
    "plt.title('Neural Network Model Loss')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training Loss', 'Testing Loss'], loc='upper right')\n",
    "print(\"Loss after final iteration: \", history.history['val_loss'][-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(model.predict(X_test.to_numpy()))\n",
    "\n",
    "#print(predictions)\n",
    "\n",
    "#print(type(predictions))\n",
    "M1= predictions.to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "predictions[M1 > 0.5] = 'normal'\n",
    "predictions[M1 <= 0.5] = 'anamoly'\n",
    "\n",
    "#print(predictions)\n",
    "\n",
    "My12=y_test.to_numpy().reshape(-1,1).copy()\n",
    "\n",
    "#y_test_labels = y_test.to_numpy().reshape(-1,1).copy()\n",
    "y_test_labels[My12 > 0.5] = 'normal'\n",
    "y_test_labels[My12 <= 0.5] = 'anamoly'\n",
    "\n",
    "\n",
    "print()\n",
    "print('accuracy', accuracy_score(predictions,y_test_labels))\n",
    "print('confusion matrix\\n', confusion_matrix(predictions,y_test_labels))\n",
    "\n",
    "print(classification_report(predictions,y_test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
